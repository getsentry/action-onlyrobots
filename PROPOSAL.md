# Proposal: Simplify AI Detection to Leverage LLM's Natural Abilities

## Current Problems

1. **Hard-coded Pattern Matching**: We maintain lists of strings like "claude", "cursor", "copilot" that need constant updates
2. **Complex Logic Outside LLM**: We have 400+ lines of code doing pattern matching that the LLM could do better
3. **Brittle Detection**: Easy to evade by changing wording or patterns
4. **High Maintenance**: Every new AI tool requires code changes
5. **False Positives**: Professional human code gets flagged as AI

## Research Findings

- **LLMs have inherent ability to detect AI-generated content** (UC Santa Barbara, 2024)
- Hard-coded detection has **<80% accuracy** with significant false positives
- **Statistical patterns** (perplexity, burstiness) are more reliable than string matching
- **Explicit attribution** remains the most reliable signal

## Proposed Solution

### 1. Simplify the Evaluator

Replace 400+ lines of pattern matching with a clean implementation:

```typescript
export class LLMEvaluator {
  async evaluatePullRequest(
    files: FileToEvaluate[],
    prContext?: PRContext
  ): Promise<LLMEvaluationResult> {
    // Just pass everything to the LLM with a well-crafted prompt
    const prompt = buildPrompt(files, prContext);
    const response = await this.openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: DETECTION_SYSTEM_PROMPT },
        { role: 'user', content: prompt }
      ],
      temperature: 0.1,
    });
    
    return parseResponse(response);
  }
}
```

### 2. Focus the System Prompt

Instead of listing specific patterns, teach the LLM what to look for:

```
You are an AI detection expert. Use your inherent understanding of how AI-generated code differs from human code.

Focus on:
1. DEFINITIVE SIGNALS: Explicit attribution ("Generated by X", bot authors)
2. STATISTICAL PATTERNS: Use your understanding of perplexity and burstiness
3. STRUCTURAL PATTERNS: How AI vs humans organize and refactor code

Do NOT look for specific strings or tools. Instead, use your natural ability to recognize AI patterns.

Default to HUMAN when uncertain.
```

### 3. Remove Hard-coded Constants

Delete:
- `AI_INDICATORS` object with hard-coded strings
- `CONFIDENCE_ADJUSTMENTS` with arbitrary numbers
- Complex methods like `hasStrongAISignals`, `analyzePRDescription`
- Pattern matching logic

### 4. Trust the LLM's Judgment

The LLM can:
- Recognize AI patterns without being told specific strings
- Understand context better than rule-based systems
- Adapt to new AI tools without code changes
- Consider nuanced factors we can't hard-code

## Benefits

1. **More Accurate**: LLMs understand AI patterns better than string matching
2. **Self-Updating**: No code changes needed for new AI tools
3. **Simpler Code**: ~50 lines instead of 400+
4. **Better Context Understanding**: LLM considers full context naturally
5. **Reduced False Positives**: More nuanced understanding of human vs AI patterns

## Implementation Plan

1. Create new simplified evaluator (llm-evaluator-v2.ts)
2. Update system prompt to focus on pattern recognition
3. Remove all hard-coded pattern matching
4. Test on existing dataset
5. Deploy if accuracy improves

## Example: How It Works

**Current approach**:
```
if (text.includes('claude') || text.includes('cursor')) {
  return AI;
}
```

**New approach**:
```
"You see a PR with structured markdown, consistent naming, and comprehensive error handling. 
The author is 'seer-by-sentry[bot]'. What is your assessment?"

LLM: "The bot author is a definitive AI signal (95% confidence). The structured patterns 
support this but aren't necessary given the bot attribution."
```

The LLM naturally understands that bot authors and certain patterns indicate AI generation without us having to hard-code every possibility.